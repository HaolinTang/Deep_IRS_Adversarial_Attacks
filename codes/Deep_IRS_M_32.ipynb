{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jjs49WHk8oGE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsLfk4MGuARk",
    "outputId": "22190bc2-87b5-493f-91e7-99e6b5090b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#load deepdataset \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "xtrain = pd.read_csv('/content/drive/My Drive/xtrain_32_10000.csv', header=None)\n",
    "ytrain = pd.read_csv('/content/drive/My Drive/ytrain_32_10000.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IaaMQ5IJwWZE"
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "xtrain = np.asarray(xtrain).astype(np.float16)\n",
    "ytrain = np.asarray(ytrain).astype(np.float16)\n",
    "\n",
    "#xtrain= F.normalize(torch.Tensor(xtrain))\n",
    "#ytrain= F.normalize(torch.Tensor(ytrain))\n",
    "\n",
    "xtrain= torch.Tensor(xtrain)\n",
    "ytrain= torch.Tensor(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkXZXjUbOs2h",
    "outputId": "2e1094f4-b797-48a7-aa6a-580ab4830211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements on IRS is1024\n",
      " The trainng data size is10000\n"
     ]
    }
   ],
   "source": [
    "print('The number of elements on IRS is' + str(xtrain.shape[1]) + '\\n The trainng data size is' + str(xtrain.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TRbN6lF2vpZF"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dcOtl2gaExoh"
   },
   "outputs": [],
   "source": [
    "# define training dataset\n",
    "train_data = TensorDataset(xtrain, ytrain)\n",
    "trainloader = DataLoader(train_data, batch_size=500, shuffle=True)\n",
    "\n",
    "# number of the elements (i.e. features)\n",
    "M = xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjMXbL_MzoIU",
    "outputId": "d99b89a9-acf6-495e-c35a-a1e838e40948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (dp1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "  (dp2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (dp3): Dropout(p=0.5, inplace=False)\n",
      "  (fc4): Linear(in_features=4096, out_features=1024, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the neural net class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=M, out_features=2*M)\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=2*M, out_features=4*M)\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(in_features=4*M, out_features=4*M)\n",
    "        self.dp3 = nn.Dropout(p=0.5)\n",
    "        self.fc4 = nn.Linear(in_features=4*M, out_features=M)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dp3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A33L1h7-zoNT"
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "#epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NKNGNVWA87Fr"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader):\n",
    "    for epoch in range(epochs): # no. of epochs\n",
    "        running_loss = 0\n",
    "        for data in trainloader:\n",
    "            # data to GPU if available\n",
    "            features, targets = data[0], data[1]\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # propagate the loss backward\n",
    "            loss.backward()\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    " \n",
    "            running_loss += loss.item()\n",
    "        print('[Epoch %d] loss: %.3f' %\n",
    "                      (epoch + 1, running_loss/len(trainloader)))\n",
    " \n",
    "    print('Done Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAqaE946-4sW",
    "outputId": "35bdd7c4-36dd-4138-81ff-43404893ffa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 0.018\n",
      "[Epoch 2] loss: 0.015\n",
      "[Epoch 3] loss: 0.013\n",
      "[Epoch 4] loss: 0.012\n",
      "[Epoch 5] loss: 0.011\n",
      "[Epoch 6] loss: 0.010\n",
      "[Epoch 7] loss: 0.010\n",
      "[Epoch 8] loss: 0.009\n",
      "[Epoch 9] loss: 0.009\n",
      "[Epoch 10] loss: 0.009\n",
      "[Epoch 11] loss: 0.009\n",
      "[Epoch 12] loss: 0.009\n",
      "[Epoch 13] loss: 0.009\n",
      "[Epoch 14] loss: 0.009\n",
      "[Epoch 15] loss: 0.009\n",
      "[Epoch 16] loss: 0.009\n",
      "[Epoch 17] loss: 0.009\n",
      "[Epoch 18] loss: 0.009\n",
      "[Epoch 19] loss: 0.009\n",
      "[Epoch 20] loss: 0.009\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "train(net, trainloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Deep_IRS_M_32.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
